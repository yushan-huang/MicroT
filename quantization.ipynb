{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import sys\n",
    "sys.path.append('./mcunet')\n",
    "from mcunet.model_zoo import net_id_list, build_model, download_tflite\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "# quant kd_mcunet\n",
    "model_path = './imagenet_kd_proxy_224.pth'\n",
    "model, image_size, description = build_model(net_id=\"proxyless-w0.3\", pretrained=False)  # you can replace net_id with any other option from net_id_list\n",
    "model.classifier = torch.nn.Identity()\n",
    "model.classifier = torch.nn.Sequential(torch.nn.Linear(384,384))\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.classifier = torch.nn.Identity()\n",
    "print(net_id_list)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "img = Image.open('./PlantCLEF_Subset/train/ash/222064.jpg')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img = preprocess(img)\n",
    "img = img.unsqueeze(0) \n",
    "\n",
    "model.eval() \n",
    "output = model(img)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,224,224)\n",
    "input_names = ['input']\n",
    "outout_names = ['output']\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    './kd_proxy_224.onnx',\n",
    "    do_constant_folding=False, # whether to execute constant folding for optimization\n",
    "    input_names=input_names,\n",
    "    output_names=outout_names,\n",
    "    opset_version=11,\n",
    "    export_params=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx output\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "img_np = img.numpy()\n",
    "\n",
    "sess = onnxruntime.InferenceSession(\"./kd_proxy_224.onnx\")\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "input_shape = sess.get_inputs()[0].shape\n",
    "\n",
    "\n",
    "if len(input_shape) == 4: \n",
    "    img_np = img_np.reshape(input_shape)\n",
    "\n",
    "output = sess.run(None, {input_name: img_np})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! onnx2tf -i ./kd_proxy_224.onnx -o ./quant_model -oiqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "img = Image.open('./PlantCLEF_Subset/train/ash/222064.jpg')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img = preprocess(img)\n",
    "img = img.unsqueeze(0) \n",
    "\n",
    "img_np = img.numpy()\n",
    "\n",
    "# for TensorFlow Liteï¼Œchange (N, C, H, W) to (N, H, W, C)\n",
    "img_np = np.transpose(img_np, (0, 2, 3, 1))\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./quant_model/kd_proxy_224_quant.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "img_np = img_np.astype(input_details[0]['dtype']).reshape(input_shape)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], img_np)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(output_data)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
